{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc911b0b-4e15-401e-9875-e43c25470daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Insert the parent directory of \"app\" into sys.path\n",
    "# so that Python recognizes \"app\" as an importable package.\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85258025-55e3-45db-b6a5-29004264c7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # This looks for .env in the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70278d01-fe4a-47fe-91e5-ff91b67a046d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomazbratanic/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/tomazbratanic/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in _VertexAIBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/tomazbratanic/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in _VertexAICommon has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from prettytable import PrettyTable\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LlamaIndexLLMWrapper\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    ")\n",
    "from google.generativeai.types import RequestOptions\n",
    "from google.api_core import retry\n",
    "\n",
    "from app.workflows.shared import graph_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4329aafd-3e8c-4acb-abdf-fcedd3f95e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomazbratanic/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import flows\n",
    "from app.workflows.naive_text2cypher import NaiveText2CypherFlow\n",
    "from app.workflows.naive_text2cypher_retry import NaiveText2CypherRetryFlow\n",
    "from app.workflows.iterative_planner import IterativePlanningFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041de039-c410-417f-bec2-9b92a70cdf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Cypher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who acted in Tom Hanks’s highest-rated movie?</td>\n",
       "      <td>MATCH (p:Person {name: 'Tom Hanks'})-[:ACTED_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which movie starring Keanu Reeves has the most...</td>\n",
       "      <td>MATCH (meg:Actor {name: \"Keanu Reeves\"})-[:ACT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who directed the most recent movie starring Ha...</td>\n",
       "      <td>MATCH (p:Person {name: \"Halle Berry\"})-[:ACTED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the highest-rated movie from the 1990s...</td>\n",
       "      <td>MATCH (m:Movie)-[:DIRECTED]-(d:Person) WHERE m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For all movies starring Keanu Reeves, find the...</td>\n",
       "      <td>MATCH (keanu:Person {name: \"Keanu Reeves\"})-[:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0      Who acted in Tom Hanks’s highest-rated movie?   \n",
       "1  Which movie starring Keanu Reeves has the most...   \n",
       "2  Who directed the most recent movie starring Ha...   \n",
       "3  What is the highest-rated movie from the 1990s...   \n",
       "4  For all movies starring Keanu Reeves, find the...   \n",
       "\n",
       "                                              Cypher  \n",
       "0  MATCH (p:Person {name: 'Tom Hanks'})-[:ACTED_I...  \n",
       "1  MATCH (meg:Actor {name: \"Keanu Reeves\"})-[:ACT...  \n",
       "2  MATCH (p:Person {name: \"Halle Berry\"})-[:ACTED...  \n",
       "3  MATCH (m:Movie)-[:DIRECTED]-(d:Person) WHERE m...  \n",
       "4  MATCH (keanu:Person {name: \"Keanu Reeves\"})-[:...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark data\n",
    "test_df = pd.read_csv('test_data.csv', delimiter=\";\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a57e472-52c6-4da0-b6ef-d3122d5c4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_flow_llm_combination(flow_name, flow, llm_name, llm, test_df, graph_store):\n",
    "    results = []\n",
    "    latencies = []\n",
    "    ground_truth = []\n",
    "    timeouts = 0\n",
    "    flow_instance = flow(llm=llm, timeout=90)\n",
    "\n",
    "    for i, row in test_df.iterrows():\n",
    "        question = row['Question']\n",
    "\n",
    "        start = time.time()\n",
    "        try:\n",
    "            data = await flow_instance.run(input=question)\n",
    "        except:\n",
    "            data = {\"answer\": \"timeout/error\", \"question\": question}\n",
    "            timeouts += 1\n",
    "        end = time.time()\n",
    "        latencies.append(end - start)\n",
    "        results.append(data)\n",
    "\n",
    "        try:\n",
    "            ground_truth.append(str(graph_store.structured_query(row['Cypher'])))\n",
    "        except Exception as e:\n",
    "            ground_truth.append(\"missing\")\n",
    "    # Create evaluation dataset\n",
    "    df = pd.DataFrame(results)\n",
    "    df['ground_truth'] = ground_truth\n",
    "    df['latencies'] = latencies\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "\n",
    "    # Run evaluation\n",
    "    result = evaluate(\n",
    "        dataset,\n",
    "        metrics=[answer_relevancy],\n",
    "        llm=LlamaIndexLLMWrapper(OpenAI(model=\"gpt-4o-2024-11-20\", temperature=0))\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'answer_relevancy': result['answer_relevancy'],\n",
    "        'avg_latency': sum(latencies) / len(latencies),\n",
    "        'timeout/errors': timeouts\n",
    "    }\n",
    "\n",
    "async def run_grid_search(\n",
    "    flows: List[callable],\n",
    "    llms: List[object],\n",
    "    test_df: pd.DataFrame,\n",
    "    graph_store: object\n",
    "):\n",
    "    results = []\n",
    "\n",
    "    for flow in flows:\n",
    "        for llm_name, llm in llms:\n",
    "            try:\n",
    "                print(f\"\\nEvaluating {flow.__name__} with {llm_name}\")\n",
    "\n",
    "                result = await evaluate_flow_llm_combination(\n",
    "                    flow_name=flow.__name__,\n",
    "                    flow=flow,\n",
    "                    llm_name=llm_name,\n",
    "                    llm=llm,\n",
    "                    test_df=test_df,\n",
    "                    graph_store=graph_store\n",
    "                )\n",
    "\n",
    "                results.append({\n",
    "                    'flow': flow.__name__,\n",
    "                    'llm': llm_name,\n",
    "                    **result\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a7173-eb21-4b46-b78e-c6dbfcab1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = [\n",
    "    IterativePlanningFlow,\n",
    "    NaiveText2CypherFlow,\n",
    "    NaiveText2CypherRetryFlow,\n",
    "]  # Add your flows\n",
    "\n",
    "google_retry = dict(retry=retry.Retry(initial=0.1, multiplier=2, timeout=61))\n",
    "llms = [\n",
    "    (\"1.5pro\", Gemini(model=\"models/gemini-1.5-pro\", temperature=0, request_options=google_retry)),\n",
    "    (\"1.5flash\", Gemini(model=\"models/gemini-1.5-flash\", temperature=0, request_options=google_retry)),\n",
    "    #(\"2.0flash\", Gemini(model=\"models/gemini-2.0-flash-exp\", temperature=0)), # rate limits\n",
    "    (\"gpt-4o\", OpenAI(model=\"gpt-4o\", temperature=0)),\n",
    "    #(\"gpt-4o-mini\", OpenAI(model=\"gpt-4o-mini\", temperature=0)),\n",
    "    #(\"o1\", OpenAI(model=\"o1-preview\", temperature=0)), no tools\n",
    "    #(\"o1-mini\", OpenAI(model=\"o1-mini\", temperature=0)), no tools\n",
    "]  # Add your LLMs\n",
    "\n",
    "results = await run_grid_search(\n",
    "    flows=flows, llms=llms, test_df=test_df, graph_store=graph_store\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4961dd5-e34c-4698-8e10-b85f9ae7a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search Results:\n",
      "+---------------------------+----------+------------------+-----------------+-----------------+\n",
      "|            Flow           |   LLM    | Answer Relevancy | Timeouts/Errors | Avg Latency (s) |\n",
      "+---------------------------+----------+------------------+-----------------+-----------------+\n",
      "| NaiveText2CypherRetryFlow |  1.5pro  |      0.686       |        0        |       6.32      |\n",
      "| NaiveText2CypherRetryFlow |  gpt-4o  |      0.639       |        0        |       9.32      |\n",
      "|    NaiveText2CypherFlow   |  1.5pro  |      0.574       |        0        |       5.84      |\n",
      "|    NaiveText2CypherFlow   |  gpt-4o  |      0.505       |        0        |       9.17      |\n",
      "| NaiveText2CypherRetryFlow | 1.5flash |      0.402       |        0        |       3.24      |\n",
      "|    NaiveText2CypherFlow   | 1.5flash |      0.398       |        0        |       2.91      |\n",
      "|   IterativePlanningFlow   |  1.5pro  |      0.132       |        21       |      24.82      |\n",
      "|   IterativePlanningFlow   |  gpt-4o  |      0.112       |        20       |      19.96      |\n",
      "|   IterativePlanningFlow   | 1.5flash |      0.094       |        23       |      16.74      |\n",
      "+---------------------------+----------+------------------+-----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "def print_results(results: List[Dict]):\n",
    "    # Create table\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Flow\", \"LLM\", \"Answer Relevancy\", \"Timeouts/Errors\", \"Avg Latency (s)\"]\n",
    "\n",
    "    # Sort results by answer relevancy\n",
    "    sorted_results = sorted(results, key=lambda x: sum(x['answer_relevancy']) / len(x['answer_relevancy']), reverse=True)\n",
    "\n",
    "    # Add rows\n",
    "    for result in sorted_results:\n",
    "        answer_relevancy = sum(result['answer_relevancy']) / len(result['answer_relevancy'])\n",
    "        timeout_errors = result['timeout/errors']\n",
    "\n",
    "        table.add_row([\n",
    "            result['flow'],\n",
    "            result['llm'],\n",
    "            f\"{answer_relevancy:.3f}\" if isinstance(answer_relevancy, (float, int)) else str(answer_relevancy),\n",
    "            f\"{timeout_errors}\",\n",
    "            f\"{result['avg_latency']:.2f}\"\n",
    "        ])\n",
    "\n",
    "    print(\"\\nGrid Search Results:\")\n",
    "    print(table)\n",
    "\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f48ba6-7981-4628-9e8c-174f7e145cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bb40af-339b-45fb-b17f-3036d155f305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76c7fc-6a54-437a-a05e-2bb8f2ba4e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
